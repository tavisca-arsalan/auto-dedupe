{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('core', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client.HotelPairsDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hotel_pairs = db.HotelPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "import json\n",
    "from bson.objectid import ObjectId\n",
    "hotel_pair = hotel_pairs.find_one({'_id':1})\n",
    "type(hotel_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c68867cdfaeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhotel_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hotel1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhotel_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hotel2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhotel_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "pprint.pprint(hotel_pair['Hotel1'])\n",
    "pprint.pprint(hotel_pair['Hotel2'])\n",
    "pprint.pprint(hotel_pair['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_jaccard_index(set_1, set_2):\n",
    "    if set_1 and set_2:\n",
    "        n = len(set_1.intersection(set_2))\n",
    "        return n / float(len(set_1) + len(set_2) - n) \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1= {\"dog\",\"cat\",\"tree\",\"osman\"}\n",
    "set2= {\"rain\",\"tree\",\"water\",\"dog\",\"cat\"}\n",
    "compute_jaccard_index(set1,set(\"rain tree dog water\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_set_similarity_with_jaccard_index(str1,str2):\n",
    "    try:\n",
    "        if (str1 and str2) and (str1!=\" \" and str2!=\" \"):\n",
    "            set1 = set(str1.split())\n",
    "            set2 = set(str2.split())\n",
    "            return compute_jaccard_index(set1,set2)\n",
    "        else:\n",
    "            raise Exception('One or more strings passed as parameters were empty or blank space!')\n",
    "    except Exception as error:\n",
    "        print('Exception: ' + repr(error))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: Exception('One or more strings passed as parameters were empty or blank space!',)\n"
     ]
    }
   ],
   "source": [
    "token_set_similarity_with_jaccard_index(\"my first name is arsalan\",\"arsalan is not my  last name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def getTermFrequency(termList):\n",
    "    termFrequencyMap = {}\n",
    "    for term in termList:\n",
    "        if term in termFrequencyMap:\n",
    "            termFrequencyMap[term]+=1               \n",
    "        else:\n",
    "            termFrequencyMap[term]=1      \n",
    "    return termFrequencyMap\n",
    "\n",
    "def cosineSimilarity(text1, text2):\n",
    "    a = getTermFrequency(text1.split())\n",
    "    b = getTermFrequency(text2.split())    \n",
    "    dotProduct = calculate_dot_product(a,b)\n",
    "    magnitudeA = calculate_word_vector_magnitude(a)\n",
    "    magnitudeB = calculate_word_vector_magnitude(b) \n",
    "    return dotProduct / math.sqrt(magnitudeA * magnitudeB);\n",
    "\n",
    "def calculate_dot_product(a,b):\n",
    "    set_a=set(a)\n",
    "    set_b=set(b)\n",
    "    intersection_set = set_a.intersection(set_b)\n",
    "    dotProduct = 0\n",
    "    for item in intersection_set:\n",
    "        dotProduct += a[item] * b[item]\n",
    "    return dotProduct\n",
    "\n",
    "def calculate_word_vector_magnitude(word_vector):\n",
    "    magnitude=0\n",
    "    for word in word_vector.keys():\n",
    "        magnitude += math.pow(word_vector[word], 2)\n",
    "    return magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6761234037828132"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTermFrequency(\"Palace in China as Hotel China Palace in China Town\".split())\n",
    "cosineSimilarity(\"Palace in China as Hotel\",\"China Palace in China Town\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object ngrams at 0x000000000910DFC0>\n",
      "thi\n",
      "his\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "sentence = 'this is a foo bar sentences and i want to ngramize it'\n",
    "n = 3\n",
    "grams = ngrams(sentence.split()[0], 3)\n",
    "for gram in grams:\n",
    "    print(''.join(gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "grams = list(ngrams('we', 3))\n",
    "print(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "def generate_three_gram_token_set(text):\n",
    "    three_gram_token_set=set()\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        three_grams=list(ngrams(token,3))\n",
    "        three_gram_token_set.update(generate_three_gram_words(three_grams))\n",
    "    return three_gram_token_set\n",
    "\n",
    "def generate_three_gram_words(three_gram_tokens):\n",
    "    three_gram_word_list =[]\n",
    "    for three_gram in three_gram_tokens:\n",
    "        three_gram_word_list.append(''.join(three_gram))\n",
    "    return three_gram_word_list\n",
    "\n",
    "def calculate_three_gram_name_similarity(text1,text2):\n",
    "    set1=generate_three_gram_token_set(text1)\n",
    "    set2=generate_three_gram_token_set(text2)\n",
    "    print(set1)\n",
    "    print(set2)\n",
    "    score = compute_jaccard_index(set1,set2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bes', 'est', 'tar'}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_three_gram_token_set('Best tar tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bes', 'est', 'tar'}\n",
      "{'bes', 'tar'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_three_gram_name_similarity(\"best tar tar\", \"bes tar tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import text_compare\n",
    "text_compare.levenshtein('test', 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
